import gradio as gr
from transformers import pipeline

# Load the model directly from the Hugging Face Hub
classifier = pipeline("text-classification", model="toothsocket/ai-detector-50k")

def analyze_text(text):
    if not text or len(text.strip()) == 0:
        return {"error": "No text provided", "aiPercentage": 0}
    
    try:
        # Split text into paragraphs (based on \n\n generated by the extension)
        paragraphs = [p.strip() for p in text.split('\n\n') if len(p.strip()) > 20]
        
        # If there are no substantial paragraphs, fallback to the original text
        if not paragraphs:
            paragraphs = [text]

        # To avoid OOM errors or timeouts, this evaluates up to the first 10 paragraphs maximum
        chunks_to_evaluate = paragraphs[:10]
        
        # Run inference on all text chunks efficiently
        results = classifier(chunks_to_evaluate, truncation=True, max_length=512)
        
        # Aggregate the AI scores across all chunks
        total_ai_score = 0
        for chunk_result in results:
            # Handle list-in-list for batch results or single dictionary
            if isinstance(chunk_result, list):
                result = chunk_result[0]
            else:
                result = chunk_result
            
            chunk_score = 0
            if result['label'] == 'LABEL_1':
                chunk_score = result['score'] * 100
            elif result['label'] == 'LABEL_0':
                chunk_score = (1 - result['score']) * 100
            
            total_ai_score += chunk_score
            
        # Average the scores
        final_score = round(total_ai_score / len(chunks_to_evaluate), 2)
                
        return {"aiPercentage": final_score}
    except Exception as e:
        return {"error": str(e), "aiPercentage": 0}

# Create a simple Gradio interface which automatically (this is used only for debugging rlly)
demo = gr.Interface(
    fn=analyze_text,
    inputs=gr.Textbox(lines=5, placeholder="Paste text here to analyze..."),
    outputs="json",
    title="HEYI AI Detector API",
    description="Backend API for the HEYI Chrome Extension. Send POST requests to `/api/predict`."
)

if __name__ == "__main__":
    # Launch the Gradio app
    demo.launch()

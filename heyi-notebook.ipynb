{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets -q\nfrom datasets import load_dataset\nimport pandas as pd\n\nprint(\"Import Success, Downloading Data\")\ndataset = load_dataset(\"shahxeebhassan/human_vs_ai_sentences\")\n\ndf = pd.DataFrame(dataset['train']) # Puts data into panda frames\n\ndisplay(df.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-03-01T05:38:30.578143Z","iopub.execute_input":"2026-03-01T05:38:30.578437Z","iopub.status.idle":"2026-03-01T05:38:44.465160Z","shell.execute_reply.started":"2026-03-01T05:38:30.578408Z","shell.execute_reply":"2026-03-01T05:38:44.464351Z"}},"outputs":[{"name":"stdout","text":"Import Success, Downloading Data\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00b1529932254ce7b4409c87498d9297"}},"metadata":{}},{"name":"stderr","text":"Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"complete_dataset.csv:   0%|          | 0.00/12.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfb0175215ac4dc8afa3a3957555965d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/105000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f25db4e05cf146b2a75d7cf4d51153f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                                                text  label\n0  Another reason why all students should have to...      0\n1  Also the Electoral College consists of 538 ele...      0\n2  Many countries have made changes in there town...      0\n3  I believe the process of choosing a president ...      0\n4  A thick cloud of carbon dioxide and heats to h...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Another reason why all students should have to...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Also the Electoral College consists of 538 ele...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Many countries have made changes in there town...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I believe the process of choosing a president ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A thick cloud of carbon dioxide and heats to h...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"!pip install transformers -q\nfrom transformers import AutoTokenizer\n\nprint(\"Import success, downloading tokenizer\")\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ntest_sentence = \"Learning to train AI is incredibly fun.\"\n\ntranslated_math = tokenizer(test_sentence)\n\nprint(\"Original English: \", test_sentence)\nprint(\"Computer Math (Token IDs): \", translated_math[\"input_ids\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-01T05:38:59.223964Z","iopub.execute_input":"2026-03-01T05:38:59.224776Z","iopub.status.idle":"2026-03-01T05:39:31.743387Z","shell.execute_reply.started":"2026-03-01T05:38:59.224723Z","shell.execute_reply":"2026-03-01T05:39:31.742456Z"}},"outputs":[{"name":"stdout","text":"Import success, downloading tokenizer\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c79fb66546b2474d947d8753c2538e58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9258779e3deb4b3195874c6f9078f1c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eed1877018fc45448af8684b93f2709e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ae422632229423489e4643343061637"}},"metadata":{}},{"name":"stdout","text":"Original English:  Learning to train AI is incredibly fun.\nComputer Math (Token IDs):  [101, 4083, 2000, 3345, 9932, 2003, 11757, 4569, 1012, 102]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Used to define translation rules\ndef tokenize_function(examples):\n    # max_length=128 means every sentence will be exactly 128 tokens long\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\nprint(\"Translating\")\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n# 3. Cleans up the dataset for the AI\ntokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n\ntokenized_datasets.set_format(\"torch\")#Format using PyTorch sensors\n\nprint(\"Dataset successfully translated\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-01T05:39:38.055326Z","iopub.execute_input":"2026-03-01T05:39:38.055851Z","iopub.status.idle":"2026-03-01T05:39:52.296445Z","shell.execute_reply.started":"2026-03-01T05:39:38.055820Z","shell.execute_reply":"2026-03-01T05:39:52.295684Z"}},"outputs":[{"name":"stdout","text":"Translating\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/105000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15cc51b9512f4180b92535d56cf56774"}},"metadata":{}},{"name":"stdout","text":"Dataset successfully translated\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\n# 1. Open the \"train\" split first, shuffle and select\ntrain_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(100000))\neval_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(90000,100000))\n\nprint(\"Loading the DistilBERT model\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\", \n    num_labels=2 # 0 for Human, 1 for AI\n)\n\n# Rules for Training\ntraining_args = TrainingArguments(\n    output_dir=\"./ai_detector_model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3, \n    weight_decay=0.01,\n    report_to=\"none\" \n)\n\n# Creates the trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n)\n\nprint(\"Initiating the training loop...\")\n\n# Trainer starts training\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-01T06:00:16.486090Z","iopub.execute_input":"2026-03-01T06:00:16.486319Z","iopub.status.idle":"2026-03-01T06:30:04.403664Z","shell.execute_reply.started":"2026-03-01T06:00:16.486295Z","shell.execute_reply":"2026-03-01T06:30:04.403065Z"}},"outputs":[{"name":"stdout","text":"Loading the DistilBERT model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca444f8339244271a841f2484784114a"}},"metadata":{}},{"name":"stderr","text":"\u001b[1mDistilBertForSequenceClassification LOAD REPORT\u001b[0m from: distilbert-base-uncased\nKey                     | Status     | \n------------------------+------------+-\nvocab_transform.weight  | UNEXPECTED | \nvocab_projector.bias    | UNEXPECTED | \nvocab_layer_norm.weight | UNEXPECTED | \nvocab_layer_norm.bias   | UNEXPECTED | \nvocab_transform.bias    | UNEXPECTED | \nclassifier.bias         | MISSING    | \npre_classifier.weight   | MISSING    | \npre_classifier.bias     | MISSING    | \nclassifier.weight       | MISSING    | \n\n\u001b[3mNotes:\n- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Initiating the training loop...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4689' max='4689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4689/4689 29:46, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.542412</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.377539</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.346446</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.232042</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.214777</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.215187</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.160118</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.138265</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.133891</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57e4fcf9972d4a1e9cc50220885700d7"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb6cd69b52f045b4a530f69b81219af7"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"217d5addbd664e00af6f4b4fbb902dff"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1472168f02b24afa92b9827ec844d268"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62381647799e475e80617e40fa740835"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1c93727f05046e0b27fc3221233fef1"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf53dd57a3cd453fa7b2dc9b9b3d8f80"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72e20c3ba6504bf881d42aaf41ddb11f"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa48d4f3f1c349179669a9ad08a694d9"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5251b6acc75e4a8c8f2e949225b14d0c"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4689, training_loss=0.2571945556523475, metrics={'train_runtime': 1787.0256, 'train_samples_per_second': 167.877, 'train_steps_per_second': 2.624, 'total_flos': 9935054899200000.0, 'train_loss': 0.2571945556523475, 'epoch': 3.0})"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score\n\n# How did we do \ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    # The AI outputs probabilities\n    final_guesses = np.argmax(predictions, axis=1) # np.argmax grabs the highest probability as its final \"guess\"\n    return {\"accuracy\": accuracy_score(labels, final_guesses)} # Compares guesses to the actual answers\n\ntrainer.compute_metrics = compute_metrics\n\nprint(\"Running evaluation\")\nresults = trainer.evaluate()\n\n# 4. Prints the final %\nprint(f\"Accuracy Score: {results['eval_accuracy'] * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-01T06:30:22.172695Z","iopub.execute_input":"2026-03-01T06:30:22.173495Z","iopub.status.idle":"2026-03-01T06:30:43.006738Z","shell.execute_reply.started":"2026-03-01T06:30:22.173459Z","shell.execute_reply":"2026-03-01T06:30:43.005915Z"}},"outputs":[{"name":"stdout","text":"Running evaluation\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [157/157 00:20]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Accuracy Score: 98.01%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install huggingface_hub -q\nfrom huggingface_hub import notebook_login\nnotebook_login() #To auto connect this to hugging face","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-01T06:31:25.648071Z","iopub.execute_input":"2026-03-01T06:31:25.648607Z","iopub.status.idle":"2026-03-01T06:31:28.949922Z","shell.execute_reply.started":"2026-03-01T06:31:25.648578Z","shell.execute_reply":"2026-03-01T06:31:28.949118Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aec3511cbddb4a32b31ca0f2e63c3cdd"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"repo_name = \"toothsocket/ai-detector-50k\"\n\nprint(\"Uploading the model...\")\nmodel.push_to_hub(repo_name)# 1. Push the trained model\ntokenizer.push_to_hub(repo_name) # 2. Push the tokenizer\n\nprint(\"Upload complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-01T06:33:58.077552Z","iopub.execute_input":"2026-03-01T06:33:58.078407Z","iopub.status.idle":"2026-03-01T06:34:05.242939Z","shell.execute_reply.started":"2026-03-01T06:33:58.078361Z","shell.execute_reply":"2026-03-01T06:34:05.242160Z"}},"outputs":[{"name":"stdout","text":"Uploading the model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"266465b077a34f86a4da9e2b4b0210f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3ba2a149cca4b77baba03530dc0aeae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77ca7d2be133437a922b728a3cc6fdc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79a8914927d045719d39041174b73bf8"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"Upload complete\n","output_type":"stream"}],"execution_count":9}]}